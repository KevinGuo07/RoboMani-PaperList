# A Paperlist for RoboMani-Learning üöÄü§ñ

[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)]()
<!--[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)-->

---

## üìå Basic Info

This repository collects the latest and influential papers and resources related to **robotic manipulation**. The focus is on:

- [Generalist Manipulation Models & Methods](#-generalist-manipulation-models-and-methods)
- [Reinforcement Learning (RL) on Robotics Manipulation](#-reinforcement-learning-rl-on-robotics-manipulation)
- [Data & Benchmarks](#-data-and-benchmarks) 
- [Hardware Projects on Robotics](#-hardware-projects-on-robotics) 
- [Interdisciplinary](#-interdisciplinary) 

Papers with **open-sourced implementations** are marked with a ‚òÄÔ∏è  
Papers with **real-world performance** reproduced by us are marked with a ‚úÖ
---

## üìö Paper List

### üß† Generalist Manipulation Models and Methods
- **DexUMI**: Using Human Hand as the Universal Manipulation Interface for Dexterous Manipulation [[paper]()] [[project]()]
- **Hume**: Introducing System-2 Thinking in Visual-Language-Action Model [[paper](https://arxiv.org/pdf/2505.21432)] [[project]()]
- **FLARE**: Robot Learning with Implicit World Modeling [[paper](https://arxiv.org/pdf/2505.15659)] [[project]()]
- **DreamGen**: Unlocking Generalization in Robot Learning through Neural Trajectories  [[paper](https://arxiv.org/pdf/2505.12705)] [[project](https://research.nvidia.com/labs/gear/dreamgen/)]
- **UniVLA**: Learning to Act Anywhere with Task-centric Latent Action [[paper](https://arxiv.org/pdf/2505.06111)] [[project]()]
- **Reactive Diffusion Policy**: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation [[paper](https://arxiv.org/pdf/2503.02881)] [[project](https://reactive-diffusion-policy.github.io/)]
- **GR00T N1**: An Open Foundation Model for Generalist Humanoid Robots [[paper](https://arxiv.org/pdf/2503.14734)] [[project](https://developer.nvidia.com/isaac/gr00t)]
- **œÄ0.5**: a VLA with Open-World Generalization [[paper](https://www.physicalintelligence.company/download/pi05.pdf)] [[project](https://www.physicalintelligence.company/blog/pi05)] ‚òÄÔ∏è ‚úÖ
- **PointVLA**: Injecting the 3D World into Vision-Language-Action Model [[paper](https://arxiv.org/pdf/2503.07511)] [[project](https://pointvla.github.io/)]
- **TraceVLA**: Visual Trace Prompting Enhances Spatial-Temporal Awareness for Generalist Robotic Policies [[paper](https://arxiv.org/pdf/2412.10345)] [[project](https://tracevla.github.io/)]
- **CogACT**: A Foundational Vision-Language-Action Model for Synergizing Cognition and Action in Robotic Manipulation [[paper](https://arxiv.org/pdf/2411.19650)] [[project](https://cogact.github.io/)] ‚òÄÔ∏è ‚úÖ
- **GRAPE**: Generalizing Robot Policy via Preference Alignment [[paper](https://arxiv.org/pdf/2411.19309)] [[project](https://grape-vla.github.io/)] ‚òÄÔ∏è
- **iDP3**: Generalizable Humanoid Manipulation with 3D Diffusion Policies [[paper](https://arxiv.org/pdf/2410.10803)] [[project](https://humanoid-manipulation.github.io/)] ‚òÄÔ∏è
- **œÄ0**: A Vision-Language-Action Flow Model for General Robot Control [[paper](https://arxiv.org/pdf/2410.24164)] [[project](https://www.physicalintelligence.company/blog/pi0)] ‚òÄÔ∏è ‚úÖ
- **ReKep**: Spatio-Temporal Reasoning of Relational Keypoint Constraints for Robotic Manipulation [[paper](https://arxiv.org/pdf/2409.01652)] [[project](https://rekep-robot.github.io/)] ‚òÄÔ∏è ‚úÖ
- **OpenVLA**: An Open-Source Vision-Language-Action Model [[paper](https://arxiv.org/pdf/2406.09246)] [[project](https://openvla.github.io/)] ‚òÄÔ∏è ‚úÖ
- **3D Diffusion Policy**: Generalizable Visuomotor Policy Learning via Simple 3D Representations [[paper](https://arxiv.org/pdf/2403.03954)] [[project](https://3d-diffusion-policy.github.io/)] ‚òÄÔ∏è ‚úÖ

### üîÅ Reinforcement Learning (RL) on Robotics Manipulation
- **TeViR**: Text-to-Video Reward with Diffusion Models for Efficient Reinforcement Learning [[paper](https://arxiv.org/pdf/2505.19769)] [[project]()] 
- **Genie Centurion**: Accelerating Scalable Real-World Robot Training with Human Rewind-and-Refine Guidance [[paper](https://arxiv.org/pdf/2505.18793)] [[project](https://genie-centurion.github.io/)] 
- **RIPT-VLA**: Interactive Post-Training for Vision-Language-Action Models [[paper](https://arxiv.org/pdf/2505.17016)] [[project](https://ariostgx.github.io/ript_vla/)] 
- **ManipLVM-R1**: Reinforcement Learning for Reasoning in Embodied Manipulation with Large Vision-Language Models [[paper](https://arxiv.org/pdf/2505.16517)] [[project]()] 
- **ReinboT**: Amplifying Robot Visual-Language Manipulation with Reinforcement Learning [[paper](https://arxiv.org/pdf/2505.07395)] [[project]()] 
- **IN‚ÄìRIL**: Interleaved Reinforement and Imitation Learning for Policy Fine-tuning [[paper](https://arxiv.org/pdf/2505.10442)] [[project]()]
- **MoRE**: Unlocking Scalability in Reinforcement Learning for Quadruped Vision-Language-Action Models[[paper](https://arxiv.org/pdf/2503.08007)] [[project]()] 
- Improving Vision-Language-Action Model with Online Reinforcement Learning [[paper](https://arxiv.org/pdf/2501.16664)] [[project]()] 
- **RLDG**: Robotic Generalist Policy Distillation via Reinforcement Learning [[paper](https://arxiv.org/pdf/2412.09858)] [[project](https://generalist-distillation.github.io/)] ‚òÄÔ∏è 
- **SERL**: A Software Suite for Sample-Efficient Robotic Reinforcement Learning [[paper](https://arxiv.org/pdf/2401.16013)] [[project](https://serl-robot.github.io/)] ‚òÄÔ∏è 

### üì¶ Data and Benchmarks

- **Guiding Data Collection**: via Factored Scaling Curves [[paper](https://arxiv.org/pdf/2505.07728)] [[project]()] 
- **DemoGen**: Synthetic Demonstration Generation for Data-Efficient Visuomotor Policy Learning [[paper](https://arxiv.org/pdf/2502.16932)] [[project](https://demo-generation.github.io/)] ‚òÄÔ∏è
- Human-Agent Joint Learning for Efficient Robot Manipulation Skill Acquisition  [[paper](https://arxiv.org/abs/2407.00299)] [[project](https://norweig1an.github.io/HAJL.github.io/)] 

- **AutoBio**: A Simulation and Benchmark for Robotic Automation in Digital Biology Laboratory [[paper](https://arxiv.org/pdf/2505.14030) [[project](https://github.com/autobio-bench/AutoBio)] 
- **Open X-Embodiment**: Robotic Learning Datasets and RT-X Model [[paper](https://arxiv.org/pdf/2310.08864)] [[project](https://robotics-transformer-x.github.io/)] ‚úÖ
- **AgiBot World Colosseo**: A Large-scale Manipulation Platform for Scalable and Intelligent Embodied Systems [[paper](https://arxiv.org/abs/2503.06669)] [[project](https://agibot-world.com/)] ‚òÄÔ∏è
- **RoboTwin**: Dual-Arm Robot Benchmark with Generative Digital Twins [[paper](https://arxiv.org/pdf/2504.13059)] [[project](https://robotwin-benchmark.github.io/)] ‚úÖ
- **SimplerEnv**: Simulated Manipulation Policy Evaluation Environments for Real Robot Setups [[paper](https://arxiv.org/pdf/2405.05941)] [[project](https://simpler-env.github.io/)] ‚úÖ
- **LIBERO**: Benchmarking Knowledge Transfer for Lifelong Robot Learning [[paper](https://arxiv.org/pdf/2306.03310)] [[project](https://libero-project.github.io/main.html)] ‚úÖ
- **DISCOVERSE**: Efficient Robot Simulation in Complex High-Fidelity Environments [[paper](https://drive.google.com/file/d/1pG8N2qBdLuqj8_wylTYgsXYGOKMhwKXB/view)] [[project](https://air-discoverse.github.io/)] ‚úÖ

### üõ†Ô∏è Hardware Projects on Robotics
- **TWIST**: Teleoperated Whole-Body Imitation System [[paper](https://arxiv.org/pdf/2505.02833)] [[project](https://yanjieze.com/TWIST/)]
- **Berkeley Humanoid Lite**: An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot [[project](https://arxiv.org/pdf/2504.17249)] [[project](https://lite.berkeley-humanoid.org/)]
- **BEHAVIOR Robot Suite**: Streamlining Real-World Whole-Body Manipulation for Everyday Household Activities [[paper](https://arxiv.org/pdf/2503.05652)] [[project](https://behavior-robot-suite.github.io/)] ‚òÄÔ∏è ‚úÖ
- **Reactive Diffusion Policy**: Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation [[paper](https://arxiv.org/pdf/2503.02881)] [[project](https://reactive-diffusion-policy.github.io/)]
- **HOVER**: Versatile Neural Whole-Body Controller for Humanoid Robots [[paper](https://arxiv.org/pdf/2410.21229)] [[project](https://hover-versatile-humanoid.github.io/)] ‚òÄÔ∏è
- **Mobile ALOHA**: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation [[paper](https://arxiv.org/pdf/2401.02117)] [[project](https://mobile-aloha.github.io/)] ‚òÄÔ∏è 


### üî¨ Interdisciplinary
- The hippocampal sharp wave‚Äìripple in memory retrieval for immediate use and consolidation [[paper](https://www.nature.com/articles/s41583-018-0077-1)]

---

## üôã Contributing

This repo is inspired by Yanjie Ze's [[Paperlist](https://github.com/YanjieZe/awesome-humanoid-robot-learning)]  
Feel free to submit pull requests for new papers, corrected links, or updated results.

---

## üìú License

[MIT](LICENSE)
